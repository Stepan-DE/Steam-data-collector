# Проект игровой аналитики Steam

## Контекст проекта
В 2025 году мной был разработан комплексный проект по игровой аналитике, включающий ETL-процесс, аналитику, серверную архитектуру и систему удалённого доступа. К сожалению, исходный код был безвозвратно утерян вместе с аккаунтом GitHub. В кратчайшие сроки я приступил к его восстановлению с нуля, используя накопленный опыт для создания улучшенной версии.

## Концепция
Steam - крупнейший игровой сервис в мире, насчитывающий более 150 тысяч игр: от масштабных AAA-проектов до небольших инди-игр. Хотя я сам не являюсь активным игроком (у меня даже нет аккаунта в Steam), мне интересен этот рынок с точки зрения данных. Этот проект позволяет глубоко погрузиться в анализ игровой индустрии, одновременно развивая навыки работы с большими данными.

## Цель проекта
Создать полный ETL-пайплайн: от парсинга данных об играх из Steam API до их загрузки в хранилище и последующего анализа. В качестве основного инструмента выбран Python благодаря скорости разработки и богатой экосистеме библиотек для парсинга и работы с базами данных. В качестве СУБД используется PostgreSQL  надёжная и производительная система, идеально подходящая для задач хранения и анализа структурированных данных.

## Масштаб данных
На первом этапе было проанализировано порядка 247 000 идентификаторов (appid) из Steam API. После фильтрации неигрового контента (DLC, обновления, устаревшие записи) осталось **153 041 полноценных игровых приложения** — именно с этим объёмом данных работает текущая версия пайплайна. Таким образом, проект охватывает **весь актуальный каталог Steam**, крупнейшего в мире игрового сервиса.

## Этапы разработки

### 1. Требования и задачи
- **Extract:** Создать эффективный парсер, быстро собирающий данные из Steam API.
- **Transform:** Очистить и преобразовать сырые данные, оставив только релевантные для анализа поля.
- **Load:** Обеспечить быструю и надёжную загрузку структурированных данных в базу данных.

Это классический ETL-процесс, который составляет основу проекта.

### 2. Подготовка окружения
- Создана директория проекта с виртуальным окружением Python для изоляции зависимостей.
- Разработана модульная структура файлов:
  - **`/appids`** - хранение файлов с идентификаторами:
    - `all_appids.txt` - все доступные appid из Steam API.
    - `working_appid.txt` - только полноценные игры (без DLC, обновлений и т.д.).
    - `working_appids(reference).txt` - неизменяемая копия рабочего списка для отслеживания прогресса.
    - `failed_appids.txt` - ID игр, которые не удалось обработать (для повторных попыток).
    - `correct_appids.txt` - успешно обработанные ID.
  - **`/configs`** - конфигурационные файлы (например, `postgre_config.py` для подключения к БД).
  - **`/session_reports`** - автоматически генерируемые отчёты о сессиях парсинга.
  - **Основные скрипты:**
    - `main.py` - оркестратор всего процесса.
    - `api_client.py` - модуль для взаимодействия с Steam API.
    - `data_unpacker.py` - обработка и трансформация JSON-данных.
    - `db_loader.py` - управление подключением и запросами к PostgreSQL.
    - `file_reader.py` - работа с текстовыми файлами (чтение/запись ID).

### 3. Реализация и описание работы
Текущая версия проекта (начальная стадия) работает по следующему алгоритму:

1. **Инициализация:** В `main.py` импортируются необходимые модули, устанавливается подключение к базе данных и регистрируется функция для корректного закрытия соединения при завершении работы.
2. **Основной цикл:**
   - Чтение очередного ID из рабочего файла (`file_reader.read_appid()`).
   - Если файл исчерпан, то завершаем работу.
   - Запрос к Steam API для получения данных об игре (`api_client.parsing()`).
   - Обработка результатов:
     - При ошибке запроса ID сохраняется в `failed_appids.txt`.
     - При успехе - в `correct_appids.txt`.
   - Извлечение нужных полей из JSON-ответа (`data_unpacker.json_unpacker()`).
   - Запись структурированных данных в PostgreSQL (`db_loader.create_game_record()`).
   - Пауза (`time.sleep(0.1)`) для соблюдения лимитов API и снижения нагрузки.
3. **Завершение:** При остановке (плановой или аварийной) автоматически генерируется отчёт о сессии, а при следующем запуске работа возобновляется с места остановки.

**Примечание об архитектуре:** Изначально рассматривалась асинхронная модель для ускорения парсинга, однако из-за строгих ограничений Steam API на количество запросов она была оказалось избыточной. Текущая синхронная реализация обеспечивает стабильность, предсказуемую нагрузку и простоту кода.

## Будущие улучшения
Проект находится в активной разработке. Планируемые этапы:

1.  **Автоматизация и оркестрация:** Настройка Apache Airflow для управления расписанием запусков пайплайна и обработкой зависимостей между задачами.
2.  **Плановое обновление данных:** Реализация инкрементального обновления для отслеживания изменений (цен, рейтингов, новых релизов) и построения исторической аналитики.
3.  **Визуализация и аналитика:** Создание автоматически обновляемых дашбордов или веб-интерфейса для исследования данных.
4.  **Улучшенный мониторинг:** Реализация промежуточной отчётности (каждые 20-30 минут) с выводом ключевых метрик: прогресс, количество ошибок, скорость обработки.
5.  **Нормализация базы данных:** Рефакторинг текущей схемы хранения. Данные будут разнесены по логическим таблицам (игры, жанры, издатели и т.д.) с установлением связей, что позволит полноценно использовать возможности реляционной СУБД и повысит эффективность аналитических запросов.
6.  **Пользовательский интерфейс:** Разработка удобного и интуитивно понятного веб-интерфейса для управления пайплайном и просмотра результатов.
7.  **Интеграция с Telegram:** Создание бота для удалённого мониторинга статуса задач и получения уведомлений.
8.  **Деплой на сервер:** Развёртывание системы на выделенном сервере для обеспечения круглосуточной работы.

---

### Ваши комментарии и вклад
Этот проект является открытым для обучения и совершенствования. Замечания, предложения и вопросы приветствуются. Если вы хотите внести вклад, пожалуйста, создайте Issue или Pull Request.

---
**Используемые технологии:** Python, PostgreSQL, Steam API, Apache Airflow/Docker (в планах), Git.
